************************************************************************************************************************************************************
PROJECT DESCRIPTION:

COMPLETE CI CD:
- commit code to github from local. when we commit new changes that should available in github. in a while our ci job should initiated , whenver ci is running it should able to replace the webapp.war file(in ansible /opt/docker), and ansible playbook should create a dockerfile, and build a image, and add tag to it and push the image to dockerhub, once the ci job replace the new image in docker hub, ci should intiate CD job. Now CD job should able to terminate the pods one by one,and should able to launch the pod with the new appl



CI job : chnage code and commit to github.jenkins will pull latest code and build code with the help of maven,and jenkins generate a artifacts(warfile)and push it on to ansible server.jenkins also execute same time to createan image with the artifact and commit it into dockerhub repo.
CD job: can be initialized by jenkins , jenkins intialize ansible playbook , this ansible playbook executes deployments and service files on k8s cluster.
- Now we integrate ci and cd. so whenver we commit code , it should give o/p in k8s cluster.
 


***********************************************************************************************************************************************************
PROJECT :

SECTION 1 : INTRODUCTION 

***********************************************************************************************************************************************************
- CICD pipleine to build and deploy a java appl.
- Git      = Local version control system
- Github   = Distributed version control system.
- Jenkins  = Contineous integration tool
- Maven    = build tool
- Ansible  = Configuration management and deployment tool
- Docker   = For containerization
- K8S      = Container management tool
* All this Env in AWS

- we developers have the source code.we commit this code to distributed VCS during development phase.Then we need to build this code for that we are going to use the CI tool jenkins. Once jenkins build the code it generates artifacts. those artifacts we need to deploy into the target env.we need one tool which can able to deploy the artifacts on target env.in this case we use Ansible as a deployment tool.It can able to deploy our appls on VM or docker containe or k8s.in this case initially we will deploy our appl on a VM then we deploy it on Docker container atlast we are going to deplpoy it in a k8s.

PATH : Git(source code)- (Check in or commit)- Github -(CI) - Jenkins - (CD) - Ansible - (Docker image push) - Docker - (Doocker image pull)- Kubernetes

- we deploy our appl 1st in vm then in 2.docker container and atlast in 3.K8s cluster.

BUILD AND DEPLOY APPL ON TOMCAT SERVER :
- to start with intially we are going to build and deploy our appl on a tomcat server. for this we set up  CICD pipeline with the help of github,jenkins, Maven and tomcat.
1.Set up Jenkins
2.SetUp and Configure maven and Git
3.SetUp tomcat server
4.Integrating GitHub,Maven,TomCat server with Jenkins
5.Create a CI and CD jenkins job and we see how we going to build and deploy on a tomcat server. Once deplpoyment is done
6.We test the deployment.
By this time we have a env with a git, github,Jenkins , Maven,Tomcat. 

DEPLOY ARTIFACTS ON TOMCAT SERVER:
- We able to commit our code on github,and jenkins is going to pull the code from github, Jenkins Build with code with the help of maven and deploy it on a  
  tomcate server.

DEPLOY ARTIFACTS ON DOCKER CONTAINER : for this we use Github,Jenkins,Maven and docker.
here we see how to set up docker env, because github,jenkins,maven is already exist.
- we see how to write docker file. 
- then create an image and container on docker host.
- Integrating docker host with jenkins
- Atlast we create a CICD job in jenkins to build and deploy on a container.
By this time we have a env with a git, github,Jenkins , Maven, but here we deploy in docker container instead of Vm(tomcat server)

DEPLOY ARTIFACTS ON CONTAINER WITH THE HELP OF ANSIBLE : 
- here we use github,jenkins,MAven,Ansible and docker.
- setup ansible server
- Integrate docker host with Ansible. 
- Ansible playbook to create an image.
- Ansible playbook to create a container.
- Integrate ansible with jenkins.
- atlast we create a CICD job to build code on ansible and deploy it on a docker container.
By this time we are going to setup this env where we pull the code from guthub,build with help of maven,  and create artifacts with the help of ansible commit those into dockerHub, also we have ansible PlayBook, to deploy on a docker container,

DEPLOY ARTIFACTS ON KUBERNETES : 
- most of the env is ready by this time except kubernetes.
- so we setup k8s in aws (EKS)
- write pod , service,deployment manifest files.
- Integrate Kubeernetes with Ansible.
- ANsible playbooks to create deployment and service.
- Atlast we create a CICD job to build code on ansible and deploy it on a Kubernetes cluster.
By this time we have all env . but here we deploy appl on k8s instead of dockerHost.


CICD :
- CONTINUOUS INTEGRATION
- CONTINUOUS DELIVERY
- CONTINUOUS DEPLOYMENT

1. CONTINUOUS INTEGRATION : we have our source code in local workstation. From there we commit into the Version control system or source code management system.Here we use Git as Version control system. Once code is available here , our continuous integration tool will pull the code automatically and build that code and run unit test then we call it as contineous integration process. During this CI process we are going to build our source code or compile our source code and generate artifacts.Once artifacts are generated we need to deploy these on target Env's. Terget env's may be changed based on the project 

necessities it may be staging,test,dev,QA,pre prod,Prod like this various env's we might have. now lets say that we want to deploy artifacts on the staging env , once it is deployed in staging env  we do the regression test and performance test. once it is passed these tests we can deploy into the prod env. During this deployment process nothing but after build we are going to deploy into the staging then prod. if we are able to do this without any manual intervenction then we called it as contineous deployment.
 
- in the continous deployment we can automatically deploy into the staging env , automatically deploy into prod env. where as if we need manual intervention or som eapprovals while deploying into a prod env then we are going to called it as contineous delivery. In continuous delivery we need a manual approval.

- in our project : 
 we have source code on our local workstation and we commit into the Github.once code is available in github our CI tool jenkins is going to pull the code and build with the help of Maven.   If this all process happens automatically then we are going to called it as Contineous integration.

- Similiarly once the artifacts are generated it will be copied on to the ansible , ansible is going to make it as a Containarized appl by creating an image 
and ansible also going to deploy the code on to the K8s.this is also going to happen automatically so this is called as CONTINUOUS DELIVERY. but to do continous deployment we may need more than 1 env.

RESOURCES : aws accunt,mobaxtrem,gitbash

Source Code : Hello world repo it Github. in that 2 modules Server and webapp. along with that we have dockerfile.whenever we want to containerize our appl then we use the dockerfile.redme.md is a default file which tells about how to use this repo. Pom.xml we need this file to build our code with the help of maven. deploy.yaml, service.yaml these files required to create our appls as pods in k8s.
- Go to source module, inside that go to src(source code) there we have 3 files. here we donyt have to go deep in this source code no need.
- in webapp modeule we have one more dir webapp insdide it we have web-inf and index.jsp. in inside.jsp contents will be visible in our browser.
- One more Repo : Simple-Devops-Project. All docs for this course.

***********************************************************************************************************************************************************

SECTION 1 : INTRODUCTION 

***********************************************************************************************************************************************************
- We already have java source code available in github. we need to integrate github with jenkins , maven with jenkins.so that we can pull the code onto jenkins and build with the help pof maven. if we need any changes to our source code , with the help pof git from our local workstation will modify it and we commit that code into getgub.
- Amazon linux version : here in our project aws launched amazon linux latest version. but due to that some of our commands doesn't work.

SETUP JENKINS SERVER : 
- Setup a linux ec2 instance.
- jenkins is a java based appl. that is the reason we should install java.
- install and start jenkins. jenkins runs on port 8080. we can access it from webui from same port no.

Setup ec2 : launch an amazon linux version 2 ec2. give name jenkins-server. in Sg add one more port 8080.
- login to ec2 in mobaxtream.
- go to jenkins download. and select stable(LTS- long term stable)  download. scroll down and select "Red Hat/Fedora/Alma/Rocky/CentOS" because even amazon linux also use the same packages. click on that we can see instructions how to install jenkins.

Instructions to indstall jenkins :
- run :
  sudo wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.repo
  sudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io-2023.key

- install amazon epel : "  sudo amazon-linux-extras install epel "  for epel packjages to install. then we have to install java.
- run " amazon-linux-extras install java-openjdk11 ". then install jenkins packages. by yum install jenkins.

- access jenkins via webUI: public_ip:8080 in chrome we will be ab;e to see jenkins UI. 
there we can see thgat we can find pswrd to login to jenkins in "cat /var/lib/jenkins/secrets/initialAdminPassword "in  ec2.

CREATE A JOB IN JENKINS : tpo create a job select create a job or new item. and give name, select freestyle project presse enter. we can see many options because jenkins purpose is to build and deploy the code. all these features come swith plugins while installing.
- give the description of job, scroll down and in Build option we cansee add build setup: "Execute windows batch command or Execute shell " etc. in this case jenkins is runnig on linux system so we shiuld choose execute shell.if it is running on windows we should choose windows.
- in execute shell give any command thatw e want tpo execute. then click apply fursts and press save. so now to execute or build a job we have an option of 'build now'. befoire tto this go to ec2 and run uptime it will show 20min.
- in jenkins ui run build now. we can see build history down. it show green tick mark. means our build is success. if we want to see console o/p for what happens in the console O/P then click on that mark. 

- Console Output

Started by user admin                ( because we logged in as admin)
Running as SYSTEM                    ( running as system)
Building in workspace /var/lib/jenkins/workspace/HemanthFirstJob             (building workspace)
[HemanthFirstJob] $ /bin/sh -xe /tmp/jenkins12180103253114192049.sh          ( trying to execute our command in temperary location)
+ echo 'Hemanth Chinnammagari'
Hemanth Chinnammagari
+ uptime
 08:09:37 up  1:05,  1 user,  load average: 0.00, 0.04, 0.07
Finished: SUCCESS

***********************************************************************************************************************************************************
INTEGRATE GIT WITH JENKINS : 
- w eare in the process of setting up a pipeline to build the code.for these so far we installed jenkins and our code is in github. use to pull code from github or any VCS our system should have git. similiar way to pull our code to jenkins we should install gitin jenkins. in jenkins cli install git. once it is done we can integrate it with github on gui.
- for that install git on jenkins isntance. then install github plugin on jenkins gui. after that configure git on jenkins GUI.
- in ec2 cli run " cat /etc/hostname " o/p:ip-172-31-11-165.ap-south-1.compute.internal. to change our hostname to jenkins-server ,do nano to hostname and edit the value to jenkins server.
- now install git : " yum install git ".  then run "git -version " we can see git version . now we need to install github plugin on GUI.
- in jenkins GUI : click on manage jenkins, there we have option of manage plugins. now select github and run install. now github plugin will be installed along with its dependencies. now after installing all dependencies go back to home page. now we need to configure jenkins. again go to manage jenkins there we have option' global tool configuration'. inside it we can setup our git. we need to tell that whenever i want to pull code from github , what is the command i should use. 
- now give name as git under Git. give 'Path to Git executable '. to find where is git installed , in ec2 run 'whereis git' it will give the location where is git intalled.o/p: 'git: /usr/bin/git /usr/share/man/man1/git.1.gz'. or else if we can execute goit perfectly then we can give patrh value is git only. if it doesnt work we can give the whereis git value. now apply and save. now i integrated github with jenkins.

***********************************************************************************************************************************************************
RUN JEKINS JOB TO PULL CODE FROM GITHUB : 
- to pull code  from github in jenkins gui : select new item and give name of job, and give description same as job'PullCideFromGitHub', now undewr source management we can see None or Git. earlier before git lugin installed we were having only none option.. now select git and give url of github/hello-world repo url.and if the repo is private then we need to give credentials. but it is public so no need of credentials.now apply and save. because we are just pulling, we haven't wrote build configurations yet. now press build now .we can see success in build history.

Started by user admin
Running as SYSTEM
Building in workspace /var/lib/jenkins/workspace/PullCodeFromGitHub
The recommended git tool is: NONE
No credentials specified
Cloning the remote Git repository 
.
.
Finished: SUCCESS  . it says successfully cloned into jenkins server.it is cloned means its code should be exist in somewhere. that is where workspace comes into picture. whenever jenkins do any build activity , it will do under workspace . now go back to ec2 and 
run :
 cd /var/lib/jenkins/workspace/
[root@ip-172-31-11-165 workspace]# ls
HemanthFirstJob  PullCodeFromGitHub   ( here i can see 2 jobs that i created. now goinside pullcodegithub )
- cd pullcodefromgithub : i can see the same content which ever present in my github repo.
- So by default jenkins is going to store all the billed related info under /var/lib/jenkins/workspace

***********************************************************************************************************************************************************
INTEGRATE MAVEN WITH JENKINS :
Steps:
- SetUp maven on jenkins server.even if we want to run our build server seperately may be we can create a dedicated Maven server and we can install over there.But to reduce the complexicity , i will use jenkins server as a build server as weel. so that is why i will install maven on same system.
- We need to set up env variables.maven is java based appl, so we need java, howeverr java already installed in jenkins server . But we need to setup path JAVA_HOME,M2,M2_HOME . these 3 are maven_env variables.
- we need to install Maven plugin on jenkins GUI.
- Configure maven and java on jenkins GUI. because we havn't told to our jenkins GUI that is where exactly java is installed.

DEMO:
- search maven installation in linux : but instead of all the process like downloading jdk,like JAva and othe rvariables we can download maven directly using link. for that search maven download.. there we can see packeges for maven."Binary tar.gz archive". copy"https://dlcdn.apache.org/maven/maven-3/3.8.8/binaries/apache-maven-3.8.8-bin.tar.gz" this link address to copy it and go to ec2.
- in ec2 run pwd . we are in root folder. run cd /opt. now download maven packages under opt. 
- to download we need to use wget command followed by the link. after downloading run ll:

[root@ip-172-31-11-165 opt]# ll
total 8104
-rw-r--r-- 1 root root 8296049 Mar  8 14:09 apache-maven-3.8.8-bin.tar.gz         it is a tar.gz   . to extract it run " tra -xvzf apache-maven-3.8.8-bin.tar.gz " . it will extractvthe package.
- now run ll we can see 'apache-maven-3.8.8'. now to make it more simple rename it to maven by ' mv apache-maven-3.8.8 maven'. run ls we can see maven.
- go inside maven we can see'bin,config ..etc' dir's. go inside bin dir. we can see'mvn' command. so inside bin run './mvn -v' this will give version of maven. if we come outside of that dir and run mvn -v we wont get o/p.. so this why we need to set it up in Env variables.
- to set it up in env variables we can either update the .bash_profile of user or we can update in env vars directly. but i want to make it available for root user only. that is where i am going tp update in bash_user. bash_ availabvle under root user directory.	

- run 'cd ~ ' it will go to root. runn 'll -a ' for hidden files. in that hidden files we can see '.bash_profile' . we need to edit this file.
- run vi .bash_profile : here we need to add java path and M2 and M2_Home path.(M2_HOME : This is the path of where apache maven is available)
and M2 is the binary directory )
- inside bash profile : add 
M2_HOME=/opt/maven
M2=/opt/maven/bin 
JAVA_HOME=/usr/lib/jvm/java-11-openjdk-11.0.18.0.10-1.amzn2.0.1.x86_64
                                                         java home path is where our jdk is available. i dont know path of jdk. so open duplicate session in mobaxtrem. run sudo su - . here we need to search for jvm.' find / -name jvm   ' whereever jvm is avaialable that is the path we are going to search for.
 # find / -name jvm
/etc/jvm
/usr/lib/jvm
/usr/share/jvm
- /usr/lib/jvm : here inside run ls we can see jdk file(java-11-openjdk-11.0.18.0.10-1.amzn2.0.1.x86_64) if i want to know this location run :
- ' find / -name java-11* '. i will get location of jdk. '/usr/lib/jvm/java-11-openjdk-11.0.18.0.10-1.amzn2.0.1.x86_64'

- finally inside .bash_profile we have to add :
"
if [ -f ~/.bashrc ]; then
        . ~/.bashrc
fi
M2_HOME=/opt/maven
M2=/opt/maven/bin
JAVA_HOME=/usr/lib/jvm/java-11-openjdk-11.0.18.0.10-1.amzn2.0.1.x86_64
# User specific environment and startup programs
PATH=$PATH:$HOME/bin:$JAVA_HOME:$M2_HOME:$M2      ( Here if i dont add $, it will just take values as m2.we given $ it will replace the value which we 
                                                    specified above).
export PATH   "

- now check $path whether our changes are effected: it is not effected. beacuse we have updated in the .bash_profile. it will be reloaded if we relogin to server as a root. or else we can execute ' source .bash_profile '. source command is going to read bash_profile and load the values whoich are updated.
- now run 'echo $path " i can see maven and maven home, java home paths updated.
- run ' mvn -v 'anywhere . i will get o/p
-so we instaleld maven, java.
- now we need to tell jenkins gui that Maven is available in "/usr/lib/jvm/java-11-openjdk-11.0.18.0.10-1.amzn2.0.1.x86_64 " location and ,maven is avaialble in "M2=/opt/maven/bin " location. for that 1st we need to install maven plugin then we need to configure it.

In jenkins GUI : go to manage jenkins:available plugins: install mavens itegration. 
- now go to manage jenkins: Global tool configuration : we can see add jdk and add mavens location options. apply and save 

***********************************************************************************************************************************************************
BUILD A JAVA PROJECT USING JENKINS : 
- previous we integrate maven with jenkins.
- now we need to create our build job so that we can build our source code which is pulled from the GitHub.
- create a new job , there we got new option 'maven project' why because we installed maven plugin.
- 'Build a maven project. Jenkins takes advantage of your POM files and drastically reduces the configuration'  means bybusing maven project we will be avoiding some of the configuration headache.
- give 'hemanthmaven' as project name. give description and select git and give git url of helloworld. and downsidew we can see Build rootPOM : pom.xml.
Because maven project always looks for pom.xml. this is how maven projects does work.( in our repo we mentioned already pom.xml so we have to specify that file here). below we see maven goals and options (search maven goals.we can see maven lifecycle goals [validate,compile,test,package,verify,install,deploy]) 
- if i use package lifecycle ,all the goals prior to that(validate,compile,test) goals will be installed,if i use install all goals prior to that will be installed).
- i will give 'clean install' in goals.apply and save.
- if i build the job it will pull the code from github and build the code with the help of maven.
- run build now : when we click on job below :it is cloning the repo.before building it identifies what are all dependencies are there and it is going to download.there are test cases, it is running them.
we can see modules got success :
Maven Project ...................................... SUCCESS [  4.178 s]
[INFO] Server ............................................. SUCCESS [  7.349 s]
[INFO] Webapp ............................................. SUCCESS [  4.238 s]
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS

-Building war: /var/lib/jenkins/workspace/HemanthMavenProject/webapp/target/webapp.war  : this job created a war file under workspace. here war file is an artifact , nothing but our build outcome.
- in cli server go to : cd /var/lib/jenkins/workspaces : we can see our jobs.
- workspaces/HemanthMavenProject/webapp/target/webapp.war  : under target section we can see our war file(which is artifacts generated)

***********************************************************************************************************************************************************
INTEGRATING TOMCAT SERVER IN CICD PIPELINE :
- previous we checked how to build our code. now we will check how to deploy our code on target env(here tomcat server)
- we set up ec2, on top of that we install tomcat server.then we create a jenkins job which will deploy on to the tomcat server.
- steps to install tomcat server :
  set up linux instance
  install java11(because tomcat runs on java)
  configure tomcate(extract and configure)
  start tomcat server
  access webUI on port 8080

Demo : create an ec2.edit sg inbounr rules to allow port 8080. login to ec2 and install java by using "amazon-linux-extras install java-openjdk11"
- to download tomcate : in apache tomact 9 website "apache-tomcat-9.0.73.tar.gz " we can see tar.gz file. now copy this link address , in ec2 go to /opt and run "wget link ". we can see downloaded tar.gz file. now to extract it run " tar -xvzf apache-tomcat-9.0.73.tar.gz ". we can see "apache-tomcat-9.0.73 "
- move that tomcat file to tomcat only by " mv apache-tomcat-9.0.73 tomcat "
- now go inside tomcat. there is a bin dir, we can start tomcat inside this bin dir. we can see "startup.sh" we can use this script to start tomcat services.
- now ec2_ip:8080 : we can see tomcat server. now press on manager app : we can see 403 access denied. because it will say the manager only accessible from a browser running on the same machine as Tomcat. If you wish to modify this restriction, you'll need to edit the Manager's context.xml file.
- means we installed tomcat in ec2. so there only we have to use browser. incase if we want to access it from outside we have to update context.xml file.
- run "find / -name context.xml " file. in this file we need to update that we will be accessing tomcat from outside of tomcat server as well.
- when we ran find we can see 2 files :
/opt/tomcat/webapps/host-manager/META-INF/context.xml  open it using vi and in xml ( if we want to comment in xml "<!-- ## --> ".in xml file we can see :Valve className=allow="127\.\d+\.\d+ " it is allowing only from local system. we will comment this line.
/opt/tomcat/webapps/manager/META-INF/context.xml  : comment the same valkue class name for local system here. these files in webapps dir.
- after commenting we need to restart our tomcat server.
- in tomcat go to bin. we can see shoutdown.sh in bin. run this to stop. after that run startup.sh to start. now in browsewr it will ask credentials.  this wherewe can find creds under tomacat directory in 'config' directory. in "user.xml"

- Update users information in the tomcat-users.xml file goto tomcat home directory and Add below users to conf/tomcat-users.xml file
 "<role rolename="manager-gui"/>      (here we added 4 roles manager-gui,script..)
 <role rolename="manager-script"/>
 <role rolename="manager-jmx"/>
 <role rolename="manager-status"/>
 <user username="admin" password="admin" roles="manager-gui, manager-script, manager-jmx, manager-status"/>
 <user username="deployer" password="deployer" roles="manager-script"/>
 <user username="tomcat" password="s3cret" roles="manager-gui"/>  "

- we created 3 users(admin,deployer,tomcat). admin have all 4 roles access,he can access from gui,jmx,status anywhere.
- deplpyer has only manager scritp access.
- tomcat has manager gui access only.
- so in gui i can use either tomcat or admin user creds. because deployer doesnt have gui access

- after saving the above file restart the service using shutdown,startup.sh for shortcut to do it:
-ln -s /opt/tomcat/bin/startup.sh /usr/local/bin/tomcatup        : here i created a linked file under usr/local/bin. from the tomcat/bin location. so that
 whenever i want to run startup.sh i can just run tomcatup. because this is the path variable " usr/loca/bin". so i dont need to specify complete path.

run "echo $PATH " echo $PATH
/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin  we can see /usr/local/bin. whenever i execute tomcatup it will find in local bin.

- do the same for shutodown.sh : ln -s /opt/tomcat/bin/shutdown.sh /usr/local/bin/tomcatdown
- do tomcatdown and tomcatup. login to tomcat gui using admin or tomcat. we can find username and paswrd above script. i can see tomcat appl manager. 
- next we deploy the code which we build on this tomcat server . so that we can able to see our app. present we can see default app.

***********************************************************************************************************************************************************
INTEGRATE TOMCAT WITH JENKINS :
- first we should integrate tomcat with jenkins, then only we can deploy code to tomcat. 
1. we need to install plugin then configure tomcat. justlike we did for maben and git. for git,maven there is a dedicated plugin.
- for tomcat we need to deploy a plugin called " Deploy to container".by using this we will be able to deploy on tomcat server.then configure tomcat server with cred's.

- Jenkins Gui : click on admin. we get an option 'configure'.and change paswrd. save and apply. come outside relogin with new pswrd. then manage jenkins to install new deploy container plugin.
- Deploy to containerVersion :This plugin allows you to deploy a war to a container after a successful build.
- configure tomcat creds : manage jenkins-> credentials -> system ->Global Credentials ->add creds: (here we will be using deployer plugin which is manager script, means if one system wants to access another system in such cases we need to use manager script roles). so we will be using deployer user with deployer plugin. so give deployer as username,pswrd both. tomcat_deployer as both id and pswrd. save and go back to dashboard.

- No its time to create a new job that too deploy the code onto tomcat server.either we can update our existimng job(hemanthmaven) or crate a new job.
create a new job : name BuildDeploy,select maven project.description:'Build code with help of maven and deploy it on tomcat server'
 give git link, select /master branch means this will pull code from master branch. goals: 'clean install ' : clean : incase any previous build cache info is there just clean it and install means execute all maven jobs till install plugin.
- we see new option 'Post-build Actions ' : this is where we deploy our code into tomcat server.because first we have to build it before deploy it. choose 'Deploy war/ear to a container '. because we installed plugin deploy to a container.if we dont istall this plugin we couldnt have seen this option. select deploy container. give the path of where war file will be available.
 - cd /var/lib/jenkins/workspace/jobname/webapp/target/ here we will get webapp.war(this is artifact)
- so give war path as : /webapp/targetwebapp.war  or we can even give '**/*.war '  here this will take and deploy it to tomcat server.
context path :empty
- select cpontaner: use tomcat *8 . 9 has some issue with this plugin. it will ask creds of tomcat. we already created creds as deployer. give them. give the tomcat url as 'http://ec2_ip:8080/'.   apply and save.
- here we created a job which will build and deploy on a target server.
- run build job.  ( the o/p already mentioned in helloworld/webapp/src/main/webapp/index.jsp ) whatever content in this file we will see in tomcat server.
- after building, artifacts shoiuld be copied to tomcat server. in tomcat artifacts will be available in webapp directory.
- in build history :

"[DeployPublisher][INFO] Attempting to deploy 1 war file(s)
[DeployPublisher][INFO] Deploying /var/lib/jenkins/workspace/BuildAndDeploy/webapp/target/webapp.war to container Tomcat 8.x Remote with context null
  [/var/lib/jenkins/workspace/BuildAndDeploy/webapp/target/webapp.war] is not deployed. Doing a fresh deployment.
  Deploying [/var/lib/jenkins/workspace/BuildAndDeploy/webapp/target/webapp.war]
Finished: SUCCESS "

- it is attempting to deploy 1 war file by using tomcat 8x.and it authenticates with credentials and deployed on the target server.
- go to tomcat gui  in manager app we can see 1 more directory webapp(application directory) if i click on this i will see "Hello welcome to simple devops"

************************************************************************************************************************************************************
DEPLOY ARTIFACTS ON A TOMCAT SERVER :
- earlier we pulled code from github to jenkins and building it using maven and deploying it on tomcat. but earlier whatever o/p we are getting on tomcat server is not relevant. I want to get some login app. for that we need to update source code. to update we can pull code to our local workstation update and commit here. once it is commited we can build and compile our code with help of maven and deploy on tomcat.

- in git bash go to project folder in desktop using cd :C:\Users\292528\Desktop\Project   : but here chnage \ to /. because it will treate it is linux so that is why i gave back slash.
- clone our hwllo world repo here and change the index.jsp file which is present in /Desktop/Project/hello-world/webapp/src/main/webapp 
- delete all the content in index.jsp. search 'form filling html code in chrome'.
- copy te code and save in index.jsp. run git status : it will show On branch master, Your branch is up to date with 'origin/master'. Changes not staged for commit: modified : index.jsp.  no changes added to commit (use "git add" and/or "git commit -a"). run git add . and run git status it will say changes to be commited : modified : index.jsp.  run ' git commit -m "modified index.jsp file" .  and run ' git push origin master'

- Above : 'git add .' : adding files to staging area 
git commit -m "modified index.jsp file" : commiting the files to local repo.
' git push origin master' : commiting changes to remote repo. we are pushing to remote repo. 
- in video he also shown how to give token in local to push code to github.
- after pushing to remote repo i can see new code in my github. 
- Now go to jenkins and run buildNow job , it will run job. go to tomcat and refresh webapp we can see the new artifacts which got generated from new code. 
- this is how i make change in my local repo and commit into github , from there we build the code.
- But i want whenever i made some changes to my code immediatly my build should trigger.

************************************************************************************************************************************************************
AUTPOMATE BUILD AND DEPLOY USING POLL SCM : 
- earler we clone the code and updated it and pushed to remote repo ,and we went to jenkins and manually executed the job to build and deploy it.
- but i dont want to or execute my jenkins job manually , whenever there is some change in the Github It should automatically identify and execute the build job and deploy the code. if we want this , then Build triggers are helpful.
- Got jenkins : if we want to change our existing job then go to Configure Job : there we can see source code management :Git, if we scroll down we can see Build Triggers :
- Build whenever a SNAPSHOT dependency is built ( By default it is choosen)
- Schedule build when some upstream has no successful builds
- Trigger builds remotely (e.g., from scripts)( If we want to build jenkins job from remote server it is used)
- Build after other projects are built
- Build periodically  ( means i want to execute my job 2 times in a day , i can mention this when i want to execute . here i need to give Crone job entry
                        Cron job is a job scheduker which tells us to trigger a job on  spec time. this will execute irrespective of our code change or not)
- GitHub hook trigger for GITScm polling
- Poll SCM    ( This also works based on cron job. here we need to schedule a job , in the specific period of time It will go and validate whjether any  
               changes in repo or not.if there are no changes build doesn't happen, if there are changes build get execute.)
[ Cron Job : *****  : minutes,hours,days, day of the month, day of the week   - this is 5 stars represent ( * represents it equals to every number)
- poll scm will look into the repo that we gave, not the entire acnt.
- so in the buildeploy :select Poll Scm and give "* * * * *". every minute if code changes. apply and save.

DEMO : change index.jsp file and commit and push to github. now go to jenkins and we can see a build job automatically got triggered*Job started by SCM chnage , previous job is started by user Admin), it will go and check my github repo.if it identifies that there is a code change then 

************************************************************************************************************************************************************

SECTION 3 : INTEGRATING DOCKER IN CICD PIPELINE 

************************************************************************************************************************************************************
SETUP DOCKER ENVIRONMENT : 
- earlier we see how to build jenkins pipeline to build the code and deploy it on a VM or Tomcat server. Now we see how to deploy the code in docker container. 
- the procedure is same , we are going to pul code and build with mavens,But instead of deploying it on a Vm i will deplpoy it in a Docker container.
- our env is ready except docker env. for this we need a docker host.On that we install Docker so that we can run docker container.
STEPS :
- setup linux ec2.install docker.start docker services.Basic docker commands.
- launch ec2 using linux-2 AMI.select SG as Tomcat sg. login to that ec2 and install docker 'yum install docker'. run service docker status it will show disabled. start docker using ' service docker start'. run docker commands we can see o/ps.

************************************************************************************************************************************************************
CREATE TOMCAT CONTAINER : 
- to rename hostname of the server : run " nano /etc/hostname ". change the name of the hostname , save and exit. in ec2 cli run "init 6" to reboot the server.
- in docker ec2 pull tomcat image " docker pull tomcat" this will pull from dockerhub.
- run a tomcat container. actually tomcat runs on port 8080. so to connect to tomcat container open port 8081 on docker host(to access tomcat from extrernal network by using docker host port 8081).
  run " docker container run -d --name tomcat-container -p 8081:8080 tomcat ". 
- search "ec2_ip:8081 " it will show tomcat website . it also shows http:404 -Not Found. : this is known error in tomcat:9,10 versions. in official tomcat docker site they explained how to solve it. to resolve this issue login to container :
- run " docker container exec -it tomcat-container /bin/bash "
 here by default inside container we jumped to "/usr/local/tomcat/ " run ls we cansee webapps dir,webapps.dist 
- we are facing tomcat 404 whenver we access tomcat from browser , it will look into appl on webapps directory.if we go inside webapps dir we dont see any conent. but they are keeping all the conents in a seperate dir webapps.dist . go inside webapps.dist. we can see host,manabger all iside web.dist. all this conent we have to copy into webapps dir. then only we can access our appl.
- run "cp -R * ../webapps "run this in webapps.dist. here ( here it is copying all conents in webapps.dist to webapps dir. -R Recursively , * means in current dir , (..) means one folder above onto webapps dir.)
- go back to webapps dir we can see all the contents. now refresh it we can see tomcat in browser.
- however all these changes we made inside container is temporary.incase if we terminate this instance and recreate it we are not able to see page again.
 Means : stop the docker tomcat container. now launch anothe rcontainer from tomcat image only with another port 8082 on docker host. search ec2ip:8082 we will see 404 error again. because whatever changes we made that is within the container. we have updated changes only on docker container.whenver we create new container with the image,whatever changes that we have done on the container it wont get effected on the image. thats why whenever we launch a new image it will come up with the same error. how to trouble shoot it : we create a docker file , wepull tomcat image.we will do customization like copying files from webapps.dist to webapps so that content will be accessable under webapps dir, we will create a image, so that changes will be captured over here.from here if we launch tomcat we dont see 404 error
************************************************************************************************************************************************************
CREATE CUSTOMIZED DOCKERFILE FOR TOMCAT: 
- run " RUN cp -R /usr/local/tomcat/webapps.dist/* /usr/local/tomcat/webapps"    this will copy all the files(*) in webapps.dist to webapps. to find webapps.dist directory in container ( in dockerhub we need to search for CATALINA_HOME : /usr/local/tomcat )

- create Dockerfile :
" FROM tomcat:latest
  RUN cp -R /usr/local/tomcat/webapps.dist/* /usr/local/tomcat/webapps "
- save and build a image from this dockerfile : "docker build -t mytomcat . " this will build mytomact image
- runa container "docker container run -d --name tomcat-cont -p 8085:8080 mytomcat ". this will launch a container and check loggin to container and search content in webapps dir we see the same contents in webapps.dist dir."
- in browser search "ec2_ip:8085" we can see tomcat server.

************************************************************************************************************************************************************
INTEGRATE DOCKER WITH JENKINS :
- we will deploy our artifacts into tomcat docker container.for that we need to integrate docker host with the jenkins.
to do that we need to create a dedicated user (we can use ec2-user but it is not recommended) so we will add dockeradmin user added to dockertool.
- then we will copy artifacts from jenkins to docker .for that we will use public Over ssh plugin. later we add DockerHost to Jenkins config systems so that we can able to communicate with docker host from jenkins.

DEMo : login to docker ec2 and run " cat /etc/passwd" : it shows list of users. we can see ec2-user.remaining all are system users.
- to check groups run "cat /etc/group": we can see a group called docker is there among lot of groups. Now we need to create a user and add into docker group to perform activities as we expected.
- create a user dockeradmin useradd is the command run " useradd dockeradmin". now setup a pswrd for him run " passwd dockeradmin " this wilkl ask to insert new pswrd. Now we add user to docker group. run " id dockeradmin" this shows this user just belongs to dockeradmin group only. now we need to add this user to docker group. so modify user " usermod -aG docker dockeradmin " : modify the dockeradminuser with -aG(add Group)
- now duplicate the tab and try to login as dockeradmin " it will say server refused our key" no supported authent methods available. means whatever key we loaded it is not right key we couldn't able to login.means it is not asking for pswrd.
- Because by default aws ec2 doesn't allow paswrd based authentication.we should explicitly enable it run " nano /etc/ssh/sshd_config" we need to edit this file if we want to edit authentrication of ec2.
- inside that file " #PasswordAuthentication yes " it is commented. we remove commented . and one more " PasswordAuthentication " we need to comment this. means now we given access  to login with pswrd.
- if we want to login without pswrd we need to create ssh keys.
- after updateing pswrd authentication details we need to reload ssh " service ssh reload".
- now relogin to ec2 using ip and it will ask user : giver user as dockeradmin and pswrd. then we can see "[dockeradmin@dockerhost ~]$"
- now integrate this dockerhost with jenkins: for that install a plugin : publish over ssh ( Send build artifacts over SSH) install plugins.
- Configure dockerhost in the jenkins. Go to manage jenkins : Configure system : scroll down we see one more plugin public over ssh : so slecet ssh server : 
 means add a new server , give name as dockerhost, hostname as privateip of ec2.give username as dockeradmin , to give pswrd go to advanced: click pswrd based authentication, it will ask passwrod give "Docker" as pswrd. and test config it give success. means we can able to communcate with docker from jenkins as a dockeradmin user.

************************************************************************************************************************************************************
JENKINS JOB TO BUILD AND DEPLOY ARTIFACTS TO DOKCERHOST : 
Job : creat a job to pull code from github, build with maven,copy the artifacts to dockerhost.once it is avaialable in dockerhost, from there copying to inside a container is easy.
- we already jave  job 'avatarNew' we go and edist that job config. 
- click on new item, give the job name. and select copy from 'avatarNew" whetever config was in avatarnew it ewill come to our new job.
- change post build actions: remove tomcat server. and give sourcefiles "webapp/target/*.war" and add prefix"webapp/taget". means this would coupyonly war files, not entire path. now save and pply the job will automatically run because we applied automatic polling.
- in docker ec2 under docker admin user we can see "webapp.war" it is owned by dockeradmin.
- now we like to copy this war file to docker container.we can copy it manually.if we are copying manually , if there are so many builds how do we makesure that our appl is successfully deplpoyed every time.that is the reason we need to update our dockerfile,to take this war file while creating a new container.that is how we deploy our appl along with tomcat.

************************************************************************************************************************************************************
UPDATE TOMCAT DOCKERFILE TO AUTOMATE DEPLOYMENT PROCESS : 
- create a docker file with the artoifacts(warfile). so that whenever we launch a new container it will come up with an appl. fo that we need to copy this war file to dockerfile. earlier we created dockerfile under root dir.instead of that we can mainatain seperate dir to keep our dockerfile and artifacts so that in future we can use that locn to create docker images.
exit from dockeradmin. and in ec2-user go to "cd /opt" here create a dir 'docker'. this docker is owned by root. In jenkins we configured that these artifacts are copied by a docker admin. that is the reason it is best practice to give the ownership of docker dir to a dockeradmin user. for that change
" chown -R dockeradmin:dockeradmin docker " run this in opt dir. means ' iam giving ownership of docker to a docker admin user'. 
- from nowonwards in my job i will tell instead of copying the artifacts on to dockeradmin home dir, i would like to copy onto /opt/docker
- copy the dockerfile that we created under root earlier to docker dir under opt. run " mv Dockerfile /opt/docker/"
- run docker]# ll -l "-rw-r--r-- 1 root root 88 Apr 16 01:55 Dockerfile" it says dockerfile is owned by root.

- also makesure that we given right previliges to the docker directory to the dockeradmin user. dockerfile is owned by root. give membership of docker to dockeradmin. so run " chown -R dockeradmin:dockeradmin /opt/docker/ ". run ll -l under docker dir. it will show "-rw-r--r-- 1 dockeradmin dockeradmin 88 Apr 16 01:55 Dockerfile " means dockerfile is owned by dockeradmin.
- now tell jenkins job to not to copy artifacts into dockeradmin user.
- in configure section atlast"ssh server section ( earlier we gave empty to remote dir , default artifacts saved to dockeradmin dir.) now we want to save artifacts onto "//opt//docker ". build the job. go to /opt/docker . we can see webapp.war file(artifact).
- now we need to create a container along with war file.then only we can access our appl from the browser. for that chnage our dockerfile:
- add one more instruction "COPY ./*.war /usr/local/tomcat/webapps " /usr/local/tomcat/webapps this is where we keep all ourt war files.
- build the image with dockerfile run " docker build -t tomcat:v1 . ".(v1 ids version for our tomcat)
run images :
[root@dockerhost docker]# docker images
REPOSITORY   TAG       IMAGE ID       CREATED         SIZE
tomcat       v1        1453a7cb049d   4 seconds ago   479MB

- run a container from image tomcate " docker container run -d --name tomcatv1 -p 8090:8080 tomcat:v1 ". here if i dont specify tomcat:v1 it will take latest.
 in chrome search "http://13.233.20.248:8090/webapp/" : we can see our webpage. we launched in container.
- but the problem here is after copyting the artifacts , i am building docker contaijer manually.But it is not a right choice. we need to tell jenkins job that once the artifacts has been copied we need to create a docker container as well.

************************************************************************************************************************************************************
AUTOMATE BUILD AND DEPLOYMENT ON DOCKER CONTAINER : 
- now i want "once code commited on to github,it should able to build it ,and create artifacts and copying artifacts onto docker Host, creating a docker image, and createing a container from it " i want all these automatically :
- update the job " BuildandDeploytodockerhost" job. go configure, scrolldown to ssh server there we can see " Exec Command" here we give docker build,docker run commands here itself. means once the artifacts has been copied, jenkins job itself going to create a image , and creating a container.
Exec command : 
" cd /opt/docker                             first go to docker locn in opt,
  docker build -t regapp:v1 .;               build an image regapp versinon1 in current dir
  docker run -d  --name appcontainer -p 8095:8080 regapp:v1 "      run a container of image in port.

- docker container prune : will dlete all the stopped containers
- docker image prune -a  : will delete all the images which doesn't have containers

 no run the buildanddeploy job. go to docker ec2 and we can see a container was launched in port 8095. now searc "ec2_ip:8095" we can see tomcat server. search"ip:8095/webapp" we can see our website.

- now in local git update code and push to github. now our job will automatically run. in job it will build successfully, and it will file while deploying. now go to docker dir we can see a war file. now run the same commands that we given in job configure. it will build job successfully. but while launching container error " container name  

************************************************************************************************************************************************************
JENKINS JOB TO AUTOMATE CICD TO DEPLOY APPLICATION ON DOCKER CONTAINER : 
- previously we tried to change code to automate build and it has been failed due to docker contaienr creation. to overcome this we can edit our config.
- to overcome this we can add stop and remove conbtaoiners in the exc command using container name.
Exec Command :
 " cd /opt/docker                            
   docker build -t regapp:v1 .;    
   docker stop appcontainer;
   docker rm appcontainer;           
   docker run -d  --name appcontainer -p 8081:8080 regapp:v1 "

- now in git change the code. we can see our job will automatically runs and will success. see container in dockerhost. it will run on port 8081. we can see our website in ec2 ip port 8081 in browser.
- but the jenkins job looks ugly because we are trying to execute multiple commands. so we will take advantage of deployment tools. we can use ansible as a deployment tool. by using ansible we can execute all the commands (docker run,rm,build) in ansible in more effieient way. even we can configure our target env whatever necessary changes are needed. like installing additional packages, creating new users,updating configurations these can be achieved with the help of ansible,

************************************************************************************************************************************************************

INTEGRATING ANSIBLE IN CICD PIPELINE : 

************************************************************************************************************************************************************
WHY WE NEED ANSIBLE : 
- earlier we were doing changes in workstation,then commiting those changes with help of git onto github, once latest code is available in git, jenkins could able to pull latest code and build it with help of maven,and it was creating dpocker images, also deploying docker containers in docker host.

 here we see jenkins as build an deployment tool , but is there any better way to handle it : this where we can use deployment tool. we already know that we using git to update any chnages , lets keep it aside for sometime. Now i use ansible as a deployment tool, so that jenkins need not to do the administrative kind of activities, becuase jenkins more efficiently work as a build tool. along with ansibel we use dockerhub, our appl are containerized at thistime , ( we need a repo incase if it is a non containerized appl means which we deplpoy directly on VM may be we can use nexus or artifactorY) but we already reached to containerized level. that is the reason we use dockerhub.  now or cicd pipleine willl become more smooth. 

- here jenkins takes code from github, and buold artifacts and copy those artifacts onto ansible server. Now it is ansibel task to create images,and deploy the containers, ansible is going to take the artifacts, and with help of dockerfile it creates a docker image,this image we can commit into dockerhub,becuaeit is a repo to store docker images. 
- wjenever we execute any ansible playbook to deploy a container , docker host communicates with dockerhub,pull the image whatever we mentioned in our playbook and create a container out of it.

1. setup ansible.
2. create a dockerhub accoiunt,repo
3. jenkins can send artifacts onto ansiel server . then manage dockerhost with the help of ansible. ( docker host is already ready)

************************************************************************************************************************************************************
ANSIBLE server INSTALLATION : 
- setup ec2     
- setup hostname
- create ansadmin user to manage ansible system
- add user to sudoers file , so that ansadmin get adminstrative previliges
- generate ssh keys , because in ansible we use key based authentication.
- also enable pswrd based authentication by default it is not enabled in ec2.
- install ansible.

Create ec2 : jenkins-server, existing sg fine, because ansible requires 22 port.
- login to ec2.  change hostname : "nano /etc/hostname " remove content and give name "ansible-server". and run init 6 to reboot or restart.
- ADD new user : " useradd ansadmin "  "passwd ansadmin: new paaswrd : Ansible "
- add ansadmin user to sudoers file : run : " visudo " to go end of file "Shift+G" or we can open " nano /etc/sudoers ".
inside sudoers add "ansadmin ALL=(ALL)    NOPASSWD: ALL " means adding user and giving previliges that i can execute anycommand without any password.save.
- enable pswrd based auth : run " nano /etc/ssh/sshd_config" : uncomment (paswrdbasedauthentication yes )and comment (paswrdbasedauthentication no)
run " service sshd reload"
- create keys for ansadmin user: so go back to ansadmin user " sudo su - ansadmin " 
- after loggin to ansuser : generate ssh keys : run "ssh-keygen" it will create private and public keys , it stores under "/home/ansadmin/.ssh/id_rsa)"\
private key is (id_rsa) public key is (id_rsa-pub)
- we can see 
"Your identification has been saved in /home/ansadmin/.ssh/id_rsa. 
Your public key has been saved in /home/ansadmin/.ssh/id_rsa.pub.  now whatever server we wish to access we need to copy this id_rsa.pub key onto target system. in target sustem we should store the copy in user home dir,we will have (.ssh)under ssh we should copy rsa.pub onto a autherized keys.\

- run "sudo su - " install ansible "yum install ansible " it says : run "amazon-linux-extras install ansible2 " but foir ansible we need python. but ec2 linux by default comes with python packages. when we ran install ansible2, we can see python libraries getting installed.
- next we need to prepare our ansible system to create docker images.for that install docker .

************************************************************************************************************************************************************
INTEGRATE DOCKER ANSIBLE WITH : 
- Hre add dockerhist to ansible as  a managed node. so that ansible control node can able to manage our dockerhost. because image is build, we need to intialize our docker host to create a container that we will do with ansible control node. means we write a playbook, that playbook will tell dockerhost, how to create a container, for that we need to add dockerhost as a client or slave to our ansible system. to enable these steps :
- on dockerhost :
 create ansadmin in    ( with ansadmin user ansible will manage dockerhost)
 add ansadmin to sudeoers file
 enable paswrd based login (once all these done our dockerHost will be ready to managed by ansible) for that: On ansible node 

- on ansible node : 
 add to host file ( add dockerhost ip address in inventary file(hosts file)
 copy ssh keys ( copy ansiblke public onto dockerhost ansadmin user ; so that password less authentication gets enabled)
 test connection(execute ping etc)

Demo :
- in dockerhost create user " useradd ansadmin " passwd ansadmin" Ansible ". run " visudo "  or " nano /etc/sudoers " add "ansadmin ALL=(ALL)       NOPASSWD: ALL " means giving root previliges.
- now we need to enable password based authentication.we already done it to check run " grep /etc/ssh/sshd_config " this will look for paswrd in the file.
 it list out all that lines. there we can see paswrd auth yes.  

- in ansible server : add docker host as a manager node ( which is managed by ansible). those called as manager node. we give in default inventry file(hostfile) run " nano /etc/ansible/hosts" . hosts has default info( how to define hosts). delete all default data. inside add private ip address of 
dockerhost. (in docker host run ifconfig. we get inet address. it is private ip of dockerhost (eth0 isthe private ip of ec2). 
- now copy ansadmin user keys onto target ansadmin user acnt. for that switch onto ansadmin user there run (ll -la) we can see .ssh(keys) go isnide .ssh we can see 2 keys(pub,private). we need to keep private key safe. copy the public key using command " ssh-copy-id privateip of dockerhoist(eth0)". we usig private ips because these all are in same vpc.
- no we added a key under ssh directory oin dockerhost
- go to sudo su - ansadmin in dockerhost. run ll -la . "cd .ssh" run ll we can see autherized keys. run cat autherized keys we can see key of andsible server.
- now check can i connect to managed system (dockerhost) from ansible : run " ansible all -m ping " ( all means whetever hosts in inventory file , connect to all those systems). we have only one host in file. 
- run the above coimmad : we can see succefully abled to connect.
 to know the uptime " ansible all -m command -a uptime " :up 1 day, 18:13,  2 users, : up for 1 day, 2 users logged in. i
- oif we run uptime in dockerhost we see the same o/p as 1 day, 2 users.
- No ansible can communicate with dockerhost without any password based authentication. So that i can instruct my dockerhost from ansible to do activities.

************************************************************************************************************************************************************
INTEGRATE ANSIBLE WITH JENKINS :
 so that jenkins able to copy artifacts onto ansible.so ansible can create image,deploy containers on docker host.
by doing this jenkins able to do build only, ansible take care of deployment activities. we do same kind of integration when we were integrating dockerhost
 with jenkins.

- durinng integration of dockerhost with henkins ,we created dedicated user on dockerhost and enabled pswrd based authentication.Once that is done we went back to jenkins and installed publish over ssh.after that we configured system and added dockerhost.
- we complited almost steps for ansible integartion with jenkins. created user, enabled ppswrd based auth in ansible. we have publish over ssh plugin already available in jenkins.

- no go to configure system and add ansible.so that jenkins could able to access ansible.by using cred's we specified in config file.
DEMo : in jenkins gui : go to manage jenkins:config system : scroll down to publish over ssh : we can see we already added dockerhost. now add ansible system : give server name"ansible-server" hostname:(privateip of ansible ec2) username:ansadmin (pswrd Ansible) apply and success: means integration of jenkins with ansible done.

- create a new jenkins job where we can build and copy artifacts on to ansible system .
- create new item "Deploy_artifacts_Ansible". copy job of buildanddeploydocker. desable poll scm for temperorly(enable later). goals are same. Under post build actions : change dockerhost to ansible server(we can see both optns because we added under publish over ssh), sourcefiles: webapp/target/*.war , same ,remove prefix : webapp/target,remotedir: //opt//docker(this dir doesn't exist in ansible system. so we will creat in ansible. and give docker dir access to ansadmin user by using"chown") same, . Change Exec_command : remove the comands(instead of commands we will be useing ansible playbook). save execute this job. now build job. after success , in ansible we can see war file under docker dir.
- now ansible job is to create an image.

************************************************************************************************************************************************************
BUILD AN IMAGE AND CREATE CONTAINER IN ANSIBLE :
- run " cat /etc/group " we see no docker group.
- install docker in ansible system. in ansadminuser run " sudo yum install docker -y " to execute as root user.
- add ansadmin user in docker group.then only we can execute docker commands as ansadmin user otherwise it will throw error.
 run " sudo usermod -aG docker ansadmin ". then run "id ansadmin" we can see user belongs to docker goup aswell.
- start dokcer " sudo service docker start "
- copy the dockerfile from dockerhost to ansible.
- build the image : it will throw error : "/var/run/docker.sock: connect: permission denied " so we give read previligies to ansadmin on this dir.
- run "sudo chmod 777 /var/run/docker.sock "
- then build image " docker build -t regapp:v1 . " : regapp:v1 image created. launch a contaier from it " docker run -t -p 8081:8080 regapp:v1 ". here we can have terminal access to container.container doest run in detatched mode whenw e used -t. if we press control c container stops.

************************************************************************************************************************************************************
ANSIBLE PLAYBOOK TO CREATE IMAGE AND CONTAINER : 
- we created ansible server, integrated with jenkins,so that jenkinsa can deploy artifacts to ansible.with those artifacts we created image manually.
- how can i make this available to our target env(dockerhost). this is where dockerhub comes into picture. we can push our image to dockerhub, and this dokcerhub can be accessable by any dockersystem(dockerhost). 
- from ansible we can instruct dockerhost to pull image from dockerhub, and launch a container. the image is customized by ansible (with artifacts) we can see appl running on dockerhost.end users can access this dockerhost(dockerhosts can be 1 or 100 they can pull from dockerhub)

- Now we create a ansible playbook that creates a docker image, we modify ansible playbook to add tags and commit into the dockerhub.so that they will availabe for target env.

DEMo : in ansible user login as ansadmin. we have dockerfile,war file in /opt/docker locn. with these 2 we create a dockerfile using ansible playbook.

ANSIBLE PLAYBOOK : to run ansible playbook we need to use command "ansible-playbook "whenever we run this command we need to provide the locn where we want to run ansible-playbook.we can provide with "-i" option i is inventary.if i dont give -i , default it takes default inventaryfile which is
 "cat /etc/ansible/hosts ". hosts is a inventary file.whetever servers in this hosts, it will execute on this. 
- here we want to execiute ansible-playbook on ansible server. for taht we add ansible-server ip in hosts. we tell ansible-playbook to exec only on ansible server. take proivate ip of ansible server by ifconfig . add inet ip to "cat /etc/ansible/hosts". mention ansible ip as group by "[ansible]" whenever i usee ansible exec command it takes ip =under ansible.

"[dockerhost] if we have multiple ips under this group , ansible-playbook execute on all these ips.
172.31.33.205
[ansible]
172.31.43.162
"
- but to make work with ansible, we should copy our ssh keys onto ansible server itself otherwise we cant able to communicate with this. to check run " ansible all -a uptime" ansible will communicate with all ips in hosts file. it communicates with dockerhost, butit cant communicate with ansible itself.this is why we shoulfd copy our own keys onto our own system. run ifconfig and copy eth0 ip. run " ssh-copy-id eth0_ip" this will copy keys onto this ip. here instead of eth0 ip  we can give localhost also because we are running in same system. run copy-id it will say" Number of key(s) added: 1" means 1 ssh key added to given ip.
Write ansible-playbook :
- in /etc/docker: run nano regapp.yaml " this is justname of file : 
regapp.yaml :
---
- hosts: ansible                #on which syst i want to execute. if it is all then ansible-playbook will run on all hosts. but i gave only ansible system
                                 under ansible whetver ips were present , on those systems this playbook will execute.
                                #if we want to run ansible as root,we can use become tru
  tasks:
  - name: create docker image               whatever i giv eunder name it treats it as a discription. while running ansible-playbook we can see this msge.
                                 to create a docker image, we can use docker modules,or excuting sh or linux command .
                                 to use (docker_image we need to do some system config)simple way is  use "command" module. this module helps us to execute 
    command: docker build -t regapp:latest .                                                            linux commands as it is.
    args:                               args is used incase if we want to move this file to some other locn still we want run without errors,args can be usd
     chdir: /opt/docker      means if this playbook is available in any directory , we can execute docker build command under this dir. 

regapp.yml:
"
---
- hosts: ansible
  tasks:
  - name: create docker image
    command: docker build -t regapp:latest .
    args:
     chdir: /opt/docker    "
 to execute run " ansible-playbook regapp.yml --check "  ( here we havnt given hosts file.so it will take dfault file. --check used to see playbook will run or not.
- run docker images we can see :
docker images
REPOSITORY   TAG       IMAGE ID       CREATED       SIZE
regapp       v1        e590ab264754   2 hours ago   479MB

- now run this "ansible-playbook regapp.yml"
docker images
REPOSITORY   TAG       IMAGE ID       CREATED       SIZE
regapp       latest    e590ab264754   2 hours ago   479MB    it created latest.. however no changes in the dockerfile or afrtifacts(2hours ago only)
regapp       v1        e590ab264754   2 hours ago   479MB

- this is how we create image using ansible playbook. nextvwe do how to push this image to dockerhub, so that dockerhost can pull image and create a container.

************************************************************************************************************************************************************
COPY IMAGE TO DOCKER HUB : 
- earlier we created ansible p,aybook which can create docker image. but we want to commit this docker image onto docker hub. for that we need docker acnt so that we can push our image to docker hub.
- login to dockerhub acnt. click on create repo if we want to give name to our image. from this if we want to commit here we can use this name.
- we can give docker image name while pushing into dockerhub.for that we use docker tags.
- in ansible server: run dokcer images we can see  
REPOSITORY   TAG       IMAGE ID       CREATED       SIZE
regapp       latest    e590ab264754   2 hours ago   479MB   
regapp       v1        e590ab264754   2 hours ago   479MB
- to commit regapp latest: we need to login to dockerhub from ansible. we can use command "docker login" to login to dockerhub from our linux system.but in real world we dont use dockerhub, we use docker registry in local system like amazon docker registry or azure registry they just hold our image.But for security reasons we can create our own docker hub registry on local system or similiar kind of dockerhub.
- "docker push regapp:latest " if i push like this it will give error because it doesnt knowto which acnt i want tto commit this image. for that we should provide our username prefix to our image . my username is (hemanth11805554) so it should be "hemanth11805554/regapp:latest" this is how we give tag.
- to push image to dockerhub i will update my docker image name for that we can use tags.
- run "docker tag image_id username/image_name:latest"  :  docker tag e590ab264754 hemanth11805554/regapp:latest ( use repo_name also instead of image_id)
- run images :
REPOSITORY               TAG       IMAGE ID       CREATED        SIZE
hemanth11805554/regapp   latest    e590ab264754   19 hours ago   479MB  
regapp                   latest    e590ab264754   19 hours ago   479MB
-  above one more image created with username?imagename:latest.we can commit this image to dockerhub)	
- run "docker push hemanth11805554/regapp:latest " go to dockerhub. and check repository we have hemanth11805554 / regapp (Contains: Image )
- wre can see to pull image "docker pull hemanth11805554/regapp:latest" from dockerhub.
- next we see how to incorporate these manual steps with ansible playbook. so that in ansible we can build,tag,commit image to dockerhub.from dockerhub dockerhost will pull image and create container of it.

************************************************************************************************************************************************************
JENKINS JOB TO BUILD AN IMAGE ONTO ANSIBLE : 
- in ansible server go to "/opt/docker" : there we have (webapp.war,regapp.yml,dockerfile). regapp.yml is ansible playbook.inside add 2 tasks(for tagging, push image to docker hub)
- regapp.yml:
"
---
- hosts: ansible
  tasks:
  - name: create docker image
    command: docker build -t regapp:latest .
    args:
     chdir: /opt/docker

  - name: create tag to push image onto dockerhub           ( adding one more task)
    command: docker tag regapp:latest hemanth11805554/regapp:latest

  - name: push docker image 
    command: docker push hemanth11805554/regapp:latest
"
- execute ansible playbook " ansible-playbook regapp.yml --check "
( the login user of dockerhub and ansible playbook in server should be same(ansadmin both not root) )
- creating imaging happens only in ansible server( like we give hosts:ansible only)
- we can limit to execute ansible playbook on particular host using limits.
- run " ansible-playbook regapp.yml --limit 172.31.43.162 ". here ip is of ansiblke server
- now go to dockerhub repo : we can see the repo is resently updated. but there is no config changes, because we havnt changed anyything.
- now i dont even want to execute this command(ansible-playbook regapp.yml --check). we can give this command to jenkins server, jenkins will initiate this ansible playbook whenever there is code change or commit.
- go to jenkins job and update it by giving ansibleplaybook to execute it whenever a code change.playbook will execute and creates a new image.
- configfure " deploy_artifacts_onto_ansible" job.scroll down to post build actions:in sshservers:ansible-server: 
add execute command " ansible-playbook /opt/docker/regapp.yml" also enable poll scm.

- Now chnage code after run 
" git add .
  git commit -m "did something"
  git push origin master"
- now job will start automatically and it creates a artifacts(war file), and artifacts copied onto ansible playbook.
- in jenkis job will success.we can see webapp.war file created latestly in /opt/docker. also run docker images we can see image newly got created (hemanth11805554/regapp  latest). indockerhub also the image will be updated latestly.
- Now pending is we have to create a container out of it.for that we write a ansible-playbook , in that we tell dockerhost to coinnect to dockerhub, pull the image and create a container out of it.

************************************************************************************************************************************************************
CREATE CONTAINER ON DOCKERHOST USING ANSIBLE PLAYBOOK:
- in the process of creating CICD pipeline , we done automation till creating image using ansible-playbook and commiting to dockerhub.
- write one more ansible playbook to create a container on dockerhost, dockerhost read the instructions, it will pull image from hub and create a container.
- crate ansible playbook :
  in ansible server login as ansadmin. go to /opt/docker." run "nano deploy_reg.yml"
deploy_reg.yml:
---
- hosts: dockerhost      ( because we deploy container in dockerhost) also (if i want to execute ansible playbook as root(give become=true, but i dont wan)
  tasks:
  - name: create docker container
    command: docker run -d --name regapp-server -p 8082:8080 hemanth11805554/regapp:latest    ( this will go hub, it checks for hema..user,inside taht acnt 
                                                                                                 we have reg:app latest image. it pulls it)
   
- run " ansible-playbook deploy_reg.yml --check	" this will show (check)whther it is success or not. 
- run " ansible-playbook deploy_reg.yml ": this pull image from remote repo(dockerhub), and launch a container. but we get error : /var/run/docker.sock:
- means go to dockerhost:  run " chmod 777 /var/run/docker.sock "
- now run "ansible-playbook deploy_reg.yml " this will pull image to dockerhost, then deploy a container from it. now in browser search(ip:port) u see our site. now if we run again "ansible-playbook deploy_reg.yml" it will throw error saying that a container with the same name is already present in target env(dockerhost). now we do how to remove container before creating another .

************************************************************************************************************************************************************
CONTENOUS DEPLOYMENT OF DOCKER CONTAINER USING ANSIBLE PLAYBOOK :
Update ansible playbook to remove existing container,remove existing image,create new container.
deploy_reg.yml:
---
- hosts: dockerhost
  tasks:
  - name: stop docker container
    command: docker stop regapp-server
    ignore_errors: yes                 (means if we have regapp containerssytop it, if we dont have dont fail playbook. we called it as error handling)
  - name: remove docker container
    command: docker rm regapp-server
    ignore_errors: yes
  - name: remove docker image
    command: docker rmi hemanth11805554/regapp:latest
    ignore_errors: yes
  - name: create docker container
    command: docker run -d --name regapp-server -p 8081:8080 hemanth11805554/regapp:latest   "

- run "ansible-playbook deploy_reg.yml" this will remove docker container, image. and create a new docker image ,container with the same name as we gave.
- in ansible we just used basic commands. to run docker images or containers in playbook we should use docker modules. search " docker_image module ansible"
 in chrome.we get ex of docker modules to use in ansible playbooks.

************************************************************************************************************************************************************
CICD TO DEPLOY ON CONTAINER USING ANSIBLE : 
- we created ansible playbooks which push images to dockerhub,and initialize our dockerhost to create acontainer and dockerhost can pull image successfully.
- now i meed automate. i dont want to execute any commands.just do change in github  so that jenkins can initiate all things. for that add one more command in jenkins"exec command" earlier we used "ansible-playbook /opt/docker/regapp.yml" one command only . now add one more command
exec command : 
ansible-playbook /opt/docker/regapp.yml;
sleep 10;              ( wait for 10sec before executing 2nd command)
ansible-playbook /opt/docker/deploy_reg.yml  "

- apply and save job. in git change code and push to github. jenkins job will run and it will run ansible playbook, to push image, to pull image to dockerhost and to run container in dokcerhost.

* till now we build code, created image and ran container automatically. but here whjenever there is update in we terminate existing image and container and creating new container.during this time end user cannot connect or access appl. another is if our container is terminated how we can come to know that it is not working or how we can create new container automatically.this is where container managemnet comes into picture. 
so we look into liverage of container management system to run our containerized appl's with high availability and fault tolerance.

************************************************************************************************************************************************************
KUBERNETES(K8S) ON AWS :
Why K8S: earlier we could able to deploy our appl on docker container scuccefully. however incase that docker container goes down there is now way to recover to overcome this we can use dokcker nateive service docker swarm or we can use container ,managemnet service like K8S. using K8s gives lot of benefits compared to swarm. we deploy our appl as pods not as containers in k8s.

K8S INSTALLATION METHODS : 
- for k8s installation we have learn env, prod env.
- in prod env : installing k8s deployment tools : here we can setup k8s using kubeadm or kops or Kubespray
                turnkey cloud solns :  we have many ways : aws,azure,alibaba cloud solns to setup k8s.
                windows in k8s :

- we setup k8s in aws using eks.
- "eksctl" is a utility that helps us to setup k8s on aws eks
- in github /devops pro/tree/master/k8s explained installing k8s using kops,kubeadm,eksctl.
 
EKS INSTALLATION PROCEDURE: 
- in aws eks console: add cluster:create : name, k8s version,  like this lot of info we need to fill.it is difficult way to create cluster because we need to switch lot of services. to make it simple we use command line utility which is "eksctl"
- using eksctl we can setup cluster in few steps.explained in k8s_setup_using_eksctl 

req's: ec2 instance (use as bootsrap image , means setup k8s using  bootstrap image) this eks ec2 communicate with eks service through aws cli that is why we need to makesure we installed awscli latest verion in ec2.
- we use kubectl command to instruct our cluster. then download and  install latest version of k8s , then we need to give executive permisioions.
-then move kubectl onto /usr/local/bin . because this is default path of linux operating system.by default whenevr we execute kubectl it will go and pick from the given locn(usrlocalbin)

-setup eksctl(utility that helps to setup eks cluster). once eks cluster setup then only we can use kubectl commands to manage our cluster. Move the extracted binary(eksctl) to /usr/local/bin

- create an IAM role and attatch to ec2 instance(bootstrap image). IAM role should have previligies(IAM,EC2,Cloudfromation)

************************************************************************************************************************************************************
SETUP BOOTSRAT SERVER(BOOTSRATP IMAGE) FOR EKSCTL :
- create ec2 instance : EKS_Bootsrap_server: sg is existing(dockerhost sg) :
- login to ec2: validate version of awscli by "aws --version "
aws-cli/1.18.147 Python/2.7.18 Linux/5.10.176-157.645.amzn2.x86_64 botocore/1.18.6

- it is 1.18. now check aws doc , to install eksctl "https://docs.aws.amazon.com/eks/latest/userguide/getting-started-eksctl.html"
- "https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html " here in linux: install latest cli using curl command there.
- then install kubectl packages "https://docs.aws.amazon.com/eks/latest/userguide/install-kubectl.html"
- once kubectl package downloaded we need to add executive permissions. run ls " we can see kubectl in ec2) 
- add executive permissions " chmod +x kubectl ". then move it to " mv /usr/local/bin "
- run echo $PATH : We get "/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin" here "/usr/local/bin" whenver we execute any command it will go and validate in thhis "/usr/local/bin" location.
- run kubect verion : will display version.

- also install ekctl packages for linux here "https://docs.aws.amazon.com/eks/latest/userguide/eksctl.html "
- after installing move it to " mv /usr/local/bin" .run eksctl version : we get o/p.

Create IAM role : create role: select use case as EC2: in policies: give ec2fullaccess,cfn(because it use cloudforation templates to setup cluster), IAM full access, also to avoid permission related issues we can use adminstartion full access ploicy. give role name as "eksctl_role). we created role. now attatch it to ec2.: in ec2 :select it:actions:security:modify role.add our eksctl role.
- now this ec2 has access to every service. because we gave the role which has admin access.

************************************************************************************************************************************************************
SETUP K8S USING EKSCTL: create a cluster in ec2.
create cluster and nodes :
"
eksctl create cluster --name cluster-name  \     (cluster name: hemanth
--region region-name \                            (region name : ap-south-1) 
--node-type instance-type \             ( if we dont specify type it take m5 large file). so give t2.small
--nodes-min 2 \
--nodes-max 2 \                       ( if we dont specify min and max , still it creates 2 nodes(instances)
--zones <AZ-1>,<AZ-2>       ( let it be any AZ in ap-spouth-1)

EX :
eksctl create cluster --name Hemanth  \  
--region ap-south-1 \                         
--node-type t2.small \               ( we havent specified az,min , max. it will take default any)
or run "eksctl create cluster --name Hemanth    --region ap-south-1   --node-type t2.small  "

- after running above commands it takes 20-25 min to complete.
- in cfn : we can see a template (eks-hemanth-cluster), that has been executing to setup our ec2 instances
- also in cli after creating clusterwe can see "/root/.kube/config" this is imp file to access our k8s cluster. we can communicate with k8s using config file to do activities.
- go to ec2 we can see 2 ec2 t2 small created.
- to communicate with k8s cluster we need to use kubectl.
- run kubectl get nodes we can see 2 nodes.
- to delete cluster " eksctl delete cluster hemanth --region ap-south-1 "
- kubectl get all
NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.100.0.1   <none>        443/TCP   70m   (k8 is by default created as a service)
- to create a pod " kubectl run webapp --image=httpd" this will create pod. we created with kubectl run command.but we use manifest files 

************************************************************************************************************************************************************
RUN K8S BASIC COMMANDS : 
- deploy a nginx appl : create nginx appl as a pod, because k8s handles with pod.our intention is to launch regapp on k8s cluster so that incase if something happens to our pod or container it should able to reprovision.so that our appl is highly available for end user.
for this create a deployment ,nginx image, with 2 replicas and exposes on pport 80.
kubectl create deployment  demo-nginx --image=nginx --replicas=2 --port=80
# kubectl deployment regapp --image=valaxy/regapp --replicas=2 --port=808
kubectl get pod
- then we expose our sewrvice,means whatvcer deployment we have , that deployment we expose on port 80 and there are diff type of services to exppose our pod at k8s level or external level among them loadbalancer is one(we can use Nodeport or clusterIP). however we ewant to access our appl from browsewr we go with loadbalancer . SO run "kubectl expose deployment demo-nginx --port=80 --type=LoadBalancer" "kubectl get services -o wide"

-  whenever we create a deployment , in backend it initiate a replicaset, and rs is going to create a pod ( we mentioned 2 rs. so it creates 2 pods). to access this pods we need to create a servuce by using expose command.so it creates a service in backedn, an dthrough serviuce we can access.service type is load balancer  , we could able to see LB on aws.

- run kubectl get all : we can see one service .create a deployment to create pods:
run "kubectl create deployment  demo-nginx --image=nginx --replicas=2 --port=80" if we dont specify replicas it will create 1. it launches pods and expose on port 80.
- run get de-loy,ment : 1 deploymentdemo-nginx
- run get repliicaset: 1 rs= demo-nginx=.desired=current=ready=2.
-get pods: 2 pods.
-if we want to chcek all resources in one go:kubectl get all: we can see pods,rs,service,deployment

- Now expose our appl on port 80,with type LB : "kubectl expose deployment demo-nginx --port=80 --type=LoadBalancer" : run get all: we can see 1 extra service of type LB , we can see it created an external LB, and is running on port 80->3739/TCP(it used some internal port(37288)to access pofd)to ecpose our appl. Here actual LB will be created in AWS.our 2 instances attatched to it. in listeners(it listens on 80 and it will foreward to 3739). access alb endpoint(amazonaws.com:80) : we can see nginx webpage.

CREATE MANIFEST FILE:
pod.yml:
apiVersion: v1
kind: Pod     (Pod,Replicaset,Deploy    first letter should be Caps)
metadata:     ( name of pod)
  name: mywebserver
spec:         ( under spec give container which one we will use)
  containers:
    - name: demo-nginx     ( name of container)
      image: nginx
      ports:
       - name: demo-nginx
         containerPort: 80
 
- to expose pod we need to create a service:
-service.yml:
apiVersion: v1
kind: Service
metadata:
   name: kplabs-service            name of service.
spec:
   ports:
   - port: 8080                      port is where service listens to( expposing service on port 80) 
     targetPort: 80                  target port is where the endpoint will listen to.( like on container which port it is running)
   type: LoadBalancer       (type of service)

- Now create pod first : " kubectl apply -f pod.yml "
- create service : " kubectl apply -f service.yml"
- run get all: we can see pod,service.
- in service lb it listens on 80, and it exposed to 8080.
- now in aws go to that LB, in instances under LB they are out of service because we created a pod,service. by creating service we got LB that LB we are accessing from external network.whenever we send req from external network to service , how does it know that it has to send it to the pod we created only.because in cluster there can be 100's of pods.that is where we use labels in pod manifest files(like pod:app=demo-app), in serviuce file we use selector(like pod:app=demo-app). now any req comes to service it looks for selector , and selector have the label, and whatever in that selector label , it forward tp pods which has the same label.

Labels & Instructors :
- copy the albe endpoint we got above in aws, and search in chrome with that.it doesnt work, because backend instances still not in service .because service doesnt know that where this req should pass.(he knows if it comes to 80, it should forward on 8080. but place doesnt know)

- pod.yml:
apiVersion: v1
kind: Pod     
metadata:    
  name: demo-app
  labels:
    app: demo-app     ( this label should be same in service defn)
spec:         
  containers:
    - name: demo-nginx    
      image: nginx
      ports:
       - name: demo-nginx
         containerPort: 80

-service.yml:
apiVersion: v1
kind: Service
metadata:
   name: demo-service            
spec:
   ports:
   - port: 8080                      port is where service listens to( expposing service on port 80) 
     targetPort: 80                  target port is where the endpoint will listen to.( like on container which port it is running)
   selector:
     app: demo-app          ( selector should be same as label in pod)
   type: LoadBalancer       (type of service)

- Now create pod first : " kubectl apply -f pod.yml ". it doesnt terminate existing pod, it just update the config of pod.
- create service : " kubectl apply -f service.yml"
- run describe service we can see :  endpoints(pod endpoinyt)

************************************************************************************************************************************************************

INTEGRATE K8S IN CICD PIPELINE :

************************************************************************************************************************************************************
WRITE DEPLOYMENT FILE :
- we can create pod kind of resource in docker as docker container.by we want to use k8s is incase if failure happend to our workloads or microservices,this k8s could be able to recreate service.
- now delete the pod we created above. now it doesnt recreate default or without our commands. now we need to change this, this is where we can use deployments.
- we already have deployment file which is regapp in dockerhub(hemanth1180554). we pull this and create a pod.also we make sureif something goes with the pod, it is going to recreate again and again. also if we commit latest image to dockerhub, our k8s is going to terminate existing pods and create new pod with the latest image.   (deployment = depl)
- deployment.yml:

apiVersion: apps/v1 
kind: Deployment
metadata:
  name: valaxy-regapp
  labels: 
     app: regapp                 till here it tells about what is our deployment name, deployment label.. now it needs a pod.because whenever we exec depl 
                                 it create pod in backend. below template tells how tpo create a pod, and what pod it as to launch)

spec:
  replicas: 2 
  selector:
    matchLabels:
      app: regapp

  template:                      template is about pod.
    metadata:
      labels:
        app: regapp
    spec:                         pod requires container. this spec tells about container dfn(where to pull image,image pulling policy(always means whenever 
                                  we execute depl file it always pull latest image)from our github repo.and contport:which port we expose this container 
                                  appl.using this info we create replicaset.in rs we can see matchlabels:app:regapp with this label we should have a pod dfn
      containers:
      - name: regapp
        image: valaxy/regapp
        imagePullPolicy: Always
        ports:
        - containerPort: 8080
  strategy:                       strategy is rolling update.which represents incase there is a new image in our github, how it create a pod with new 
                                  image.lets say we have 2 replicas above.it won't delet both.at a time it will delet one container.and ceate a new 
                                  container with new image, it will makesure that new container  is serving the appl properly then it will terminate 2nd 
                                  one,and create new contaienrnwith latest image.this is how we makes sure our appl is not going down.
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 1

- this is how we wroite depl file. but for this depl we need service file .
service.yml:
apiVersion: v1
kind: Service
metadata:
  name: valaxy-service
  labels:
    app: regapp 
spec:                   
  selector:                 (selector means which deployment it should select. selector info and depl label should match.
    app: regapp 

  ports:
    - port: 8080             (on whichj port we exposing our service at cluster level)
      targetPort: 8080        (tergetport:whenever a new req comes to our LB , on which port no it is going to talk with container)

  type: LoadBalancer           (type of service is LB)

* we need to make sure the label we given at depl should match with selector in service. also we need to give whatver [port we used in container port , we should use the same port in targetport.

- use serv.yml,depl.yml to create pod and access the pods :

- in ec2 after launching k8s cluster. get all we have default service.run ls we have depl.yml,serv.yml.
- run apply depl.yml. it will create 1 depl, 2 pods,1 rs of 2 pods. now our regapp is running, i want to access it, we cant access directly.run get pods -o wide. we can see 1 pod in each ec2(2 ec2s total= 2nodes)
- now i want to create a service in such a way that the traffic should flow to any of these containers.for that apply serv.yml of type LB. now get all.we can see a LB under serrvices.
- run describe service. we can see name, port:8080(lb listens on port 8080) and sending traffic to 8080(target port). endpoints(our pods in nodes)each pod has one ip.(in node there can be multiple pods. so each pod in a node has diff ip)

- Now in aws under LB copy lb endpoint. alspo in listeners lb is listening on port 8080. so search(endpoint(elb.aws.com:8080). now we are able to access tomcat webpage directly.search(endpoint:8080/webapp) we get our webpage). meands we can see our web page in one of pod running in k8s cluster.
- run get pods. delet one pod(kubectl delete pod name_ofpod). now run get pods we can see one more pod gets launched now in avaialable nodes in cluster.because rs makesure that we are having 3 pods any point of time.

- Now integrate our k8s in cicd pipeline.for that first i need to integrate this with ansible. because i cant run this kubectl commands manually.i will tell ansible to run kubectl commands whenever we want to do the new depl.this is how we yuse ansible to deploy latest apll on k8s cluster.

************************************************************************************************************************************************************
INTEGRATE K8S BOOTSRAP SERVER WITH ANSIBLE:
- integrate k8swith ansible: we already done sam ekind with docker:here we are managing k8s with bootsrap image. that is why we integrate ansible with bootsrap image.not with cluster.
- in boosrap ec2: 
   create ansadmin user
   add ansadmin to sudoers file 
   enable pswrd based login

- in ansible node :
   we need to add bootsrap image to hosts file(inventary file)
   copy ssh keys 
   test connection 

- login to ansible ec2 as ec2 -user
- also login to bootsrap image: 
 create user " useradd ansadmin"
add user to sudoers file "visudo" and add " ansadmin ALL=(ALL)     NOPASSWD: ALL "   under (allow root to run any commands anywhere) allowing ansadmin without pswrd.
- enable pswrd based authentication" nano /etc/ssh/sshd_config " uncomment pswrd authe yes, comment pswrd auth no. runservice sshd reload.now we can login to this ec2 as a ansadmin.

- now go back to ansible server as ansadmin : go to cd /opt/docker . here we have dockerfile,war file,depl_reg.yml, regapp.yml(this creates an image and push to dockerhub. we dont change this now).
- but we change depl_reg.yml(because we were deploying it on a docker container. now we need to deploy in k8s as a pod).
- now add bootsrap image to hosts file.run "nano hosts" create a group called [kubernetes] and give private up of bootsrap . we get it when we run ifconfig in bootsrap.) add that ip in ansible hosts.also add ansible server private ip in hosts.also add localhost.
- now copy ssh keys onto the bootsrap private ip address 
- run " ssh-copy-id private_ip_of_bootsrapserver " before setup for ansadmin pswrd in bootsrap then run the copy command.
- now check the systems connection using hosts file " ansible -i hosts all -a uptime"

************************************************************************************************************************************************************
CREATE PLAYBOOKS FOR DEPLOY AND SERVICE FILES:
- now i want to execute deployments and service files using ansible.for that we create ansible playbook 
- before running ansible playbook as root, we need to copy ssh keys to k8s server.
- so run "ssh-copy-id root@privateip_k8s" it will ask k8sec2 root pswrd. in k8s ec2 run "passwd root". it will ask new pswrd. enter.
- in ansibleserver : /opt/docker : 
run "nano deployment.yml"

---
- hosts: kubernetes                 ( this playbook will execute in bootsrap image we added as k8s in hosts)
  user: true                      ( i want to execute this as root user. )
  
  tasks:
  - name: deploy regapp on k8s
    command: kubectl apply -f regapp_deployment.yml        here regapp_depl.yml will create in root directory in bootsrap image.

run " nano service.yml":

---
- hosts: kubernetes
  become: true

  tasks:
  - name: deploy regapp on k8s
    command: kubectl apply -f /root/regapp-service.yml               end.

- now exec the playbook so that target env(bootsrap) will create pods and services.
- run "ansible-playbook -i /opt/docker/hosts deployment.yml" run get pods in k8s ec2 we can see 2 pods.
- run "ansible-playbook -i /opt/docker/hosts service.yml" get all we can see lb service.

************************************************************************************************************************************************************
CREATE JENKINS DEPLOYMENT JOB FOR K8S :
- till noew we created k8s env, we careted depl,service files,and we integrated with ansible.we initialize denpl and service file using playbooks
- Now we use jenkins rather than manually executing that playbooks.
- i create a jenkins depl job.it initialize ansible playbook to intitialize deploy and serv files on k8s.
- in jenkins server: create new job:k8s_Deploy :now go with free style project(we dont want any build job): give description:dont choose any git: go to post build actuons directly:select send build artifacts on ssh: select ansible server( we want t execute on ansible server):dont give any source files or anything: in
 exec command: "ansible-playbook -i /opt/docker/hosts /opt/docker/k8s_deployment.yml
                ansible-playbook -i /opt/docker/hosts /opt/docker/k8s_service.yml    apply and save

- now press build job : it will initialize playbook on ansible, ansible is goimg to deploy depl,servc files of the k8s cluster.( before running job delete all existing depl,service files)
- run job we can see service,depl created in cluster.
- now merge both files of depl and serv and create as :k8s_all.yml
---
- hosts: kubernetes
#  becomes: true
  user: root

  tasks:
  - name: deploy regapp on k8s
    command: kubectl apply -f regapp_deployment.yml
  - name: create service for regapp
    command: kubectl apply -f regapp_service.yml
- now update job exec command:ansible-playbook -i /opt/docker/hosts /opt/docker/k8s_all.yml
- run job now : we can see job success. in k8s ec2 run all : we can see same k8s objects, because we havent changed anything.

- so depl is working as expected. but now we build the code now we see depl going to replace our pods or not.

************************************************************************************************************************************************************
CI JOB TO CREATE IMAGE FOR K8S:
- previous we cretaed a job to execute depl,serv files of k8s, because we want to know if there any changes to our source code we need to build that job and it should create a latest image in dockhub.and with that latest image we need to deploy our pods.
- in cluster run get [pods. we can see pods are running and they are cretaed from hemanth1180/regapp image( image in dokchub). Now i want to update this image by changing source code,so that our k8s should deploy with latest code.this is how we can automate entire cicd pipeline.
- so far we created only CD job(k8s_CD above).
 Now we need to create CI job that needs to pull code from Github,and build in jenkins,and run ansible playbook in our ansible server that is (regapp.yml alreafdy in /opt/docker/regapp.yml it create image from dokcerfile, add tags,  and push to dockerhub) for this we used(deploy_artifacts_ansible job)
- Now edit the existing job(deploy_artifacts_ansible this executes whenver there ic change in the source code). Create CI job with this job.
- New item(K8s_CI job): copy from :deploy_artifacts_ansible: build code with help of maven and create image on ansible and push it onto dockerhub: give git hub to pull: branch master, poll scm,in post build actions ,give exec command: ansible-playbook -i/opt/hosts/k8s_all.yml.
- now change source code, and commit. job will run.it will replace war file,run docker images in ansible server, we can see latest image created.go to dockerhub we can see latest image.
- Now we need to imtegrate our CICD job. So that whenever ci is success it should intialize CD job , and cd job shiuld take the latest image from dockerhub and do tje latest deployment.

************************************************************************************************************************************************************
ENABLE ROLLING UPDATE TO CREATE POD FROM LATEST DOCKER IMAGE: 
CI job : chnage code and commit to github.jenkins will pull latest code and build code with the help of maven,and jenkins generate a artifacts(warfile)and push it on to ansible server.jenkins also execute same time to createan image with the artifact and commit it into dockerhub repo.
CD job: can be initialized by jenkins , jenkins intialize ansible playbook , this ansible playbook executes deployments and service files on k8s cluster.
- Now we integrate ci and cd. so whenver we commit code , it should give o/p in k8s cluster.

- in CI job there is a option to intialize another jenkins job: so that once ci job completes cd job will take that image and do the deployments.
- in ci job: at end we have post build action: build othe projects : then give"trigger only if build stable( and give k8s_CD job) apply and save.
- change code and commit.
- now run get all in k8s server: we can still see old pods(running from old), they could able to recoginese changes untiull and unless we change the depl and serv files.
- for that edit"k8s_all.yml file /docker "
k8s_all.yml:

---
- hosts: kubernetes
#  becomes: true
  user: root

  tasks:
  - name: deploy regapp on k8s
    command: kubectl apply -f regapp_deployment.yml

  - name: create service for regapp
    command: kubectl apply -f regapp_service.yml

  - name: update deployment with new pods if image updated in docker hub
    command: kubectl rollout restart deployment.app/hemanth-regapp       ( "deployment.app/hemanth-regapp" we get this under service name when we run get all in k8s server. ) this will replace our depl with latest image


























